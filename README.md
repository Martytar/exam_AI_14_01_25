Для корректной работы удостоверьтесь, что установлен пакет matplotlib (необходим для отображения графиков)
Питон используйте версии 3.11  выше (необязательный пункт, но так всем будет проще)

Для проверки конкретного задания экзамена просто раскомментируйте фрагмент кода в файле main. 
В результате работы вам будет выдан ответ (будь то значение перцептрона и к-ты нейронов, к-ты регрессии или к-ты разделяющей прямой)
Также для 2 и 3 задач предусмотрено графическое отображение результата

Все структуры и методы описаны в файле ai.py.

Perceptron - класс, описывающий многослойный перцептрон (число нейронов в слое, число слоев и входов может быть задано при создании объекта)
Нейроны перцептрона по умолчанию имеют сигмоидную функци активации

svm -  метод опорных векторов, реализованный градиентным спуском в дополнение к методу внешних штрафов. Неэффективен и в решении не используется

gradient - метод получает на вход функцию, производную, начальную точку и требуемую малость градиента. Минимизирует функцию, используя градиентный спуск. Критерий остановки алгоритма: норма градиента в точке <= заданной малости градиента (e)
Возвращает точку примерного локального минимума функции (в рамках экзамена применялся для нахождения к-в линейной регрессии)

neuron_math - специальный метод, не имеет общего назначения и призвал ТОЛЬКО решить задачу моделирования булевой функции 3 параметров с использованием 2х-слойной сети с 3 входами и со ступенчатой функцией активации на каждом слое.
Возвращает совокупность неейронов, удовлетворяющих задаче. Принимает на вход (samples - тестовые данные float[][], targets - целевые значения выходов float, min и max - минимальные и максимальные значения весов на каждом нейроне float[], 
step - шаг изменения весов для каждого нейрона). Алгоритм обучения сравним с полным перебором весов в промежутке (min, max).

Тестовые данные для задач 2 и 3 хранятся в файлах samples_second_task.txt и samples_third_task.txt

По всем вопросам обращайтесь на почту martynov.bogdan.ru@gmail.com
